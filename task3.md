# ViT学习笔记

## 引言

一开始，基于自注意的架构是自然语言处理(NLP)领域的首选模型，后来受到启发，多项研究尝试将类似CNN的架构与自注意相结合，但是由于使用了专门的注意力模式，尚未在现代硬件得到有效扩展。后来又受到NPL中变换器缩放成功的启发。于是便有了ViT模型的核心思想：将图像分割成小块(patch)，将这些小块视为tokens，并将这些小块的线性嵌入序列作为变换器的输入，以监督学习的方式对模型进行图像分类训练。

## 架构分析

### 输入图像处理(补丁嵌入)

1.**图像分块**：ViT首先将图像分成一组patches。每个patches被视为Transformer的一个token。举个例子，图像大小：224 x 224    划分成16 x 16的patch，则会得到14 x 14=196个patch

2.**线性嵌入**：标准变换器的输入是一维标记嵌入序列，为了处理二维图像，我们将每个patch展平成一维向量，并通过线性层将这些向量嵌入到特殊的维度D(变换器的所有层都使用恒定的潜向量大小D)

3.**位置编码**：位置嵌入被添加到补丁嵌入中，以保留位置信息

### Transfomer编码器

1.**多头自注意力机制**：使用多个自注意力头来捕捉不同特征维度之间的关联。每个patch对其他所有patch的内容进行注意力计算，生成全局特征

2.**MLP块**：由多个线性层和激活函数组成：input(线性层)--->激活函数------>output(线性层)

3.**交替结构**：先经过自注意力层处理，然后经过MLP块处理

4.**残差连接**：将输入和输出相加，以便在训练过程中缓解梯度消失的问题

### 分类头

1.**CLS Token**：与BERT相似，ViT 在输入的 tokens 序列前加上一个特殊的 [CLS] token，用于最终的分类任务。这个 token 在整个 Transformer 编码器中被关注和更新，最后的输出向量会被用来进行图像分类。

2.**输出层**：最终[CLS]token的输出用过一个全连接层，预测图像的类别

## 关键技术创新点

1.**将图像转换为序列输入**：相比于卷积神经网络直接处理整个图像而言，ViT分割成patch，从而使得图像处理可以通过序列模型来完成

2.**引入Transformer**：将原始的transformer应用于计算机视觉架构，相较于CNN的局部卷积操作，Transformer能够在图像中捕捉到更全局的特征

3.**消除卷积操作的先验偏差**：CNN具有局部性偏差，权重共享，和平移不变性的固有归纳偏差。这对于某些任务是有益的，但也可能限制模型的表达能力。而ViT的自注意力机制能够在输入图像的全局范围内进行操作，不依赖于局部特征。(据论文所述，大规模数据集，CNN的固有归纳偏差被完虐)

补充：应该是我自己学习不仔细的原因，尽然学到这才知道固有偏差这个词，但是还好了解到了。

局部性偏差---CNN使用卷积核对图像进行局部区域的处理，假设图像中的特征可以通过领域内像素之间的关系来表示。关注局部特征，减少不必要的计算，提高效率和泛化能力

平移不变性---卷积操作和池化层使得CNN对图像的平移不敏感，即使物体在图像中的位置发生了变化，模型仍然可以识别出这些特征。减少训练数据需求

权重共享---CNN中的卷积核在图像的所有区域共享同样的权重，意味着模型在不同位置应用相同的滤波器。大大减少了模型需要学习的参数数量。比完全连接的神经网络更加高效，并降低了过拟合的风险

## ViT与CNN的区别(自己总结，不一定全)

|                | ViT                                      | CNN                                    |
| -------------- | ---------------------------------------- | -------------------------------------- |
| 基本架构       | Transformer                              | 卷积操作                               |
| 局部性vs全局性 | 通过自注意力机制，能够捕捉输入的全局特征 | 适合捕捉局部特征                       |
| 训练数据       | 需要大量数据                             | 在中小数据集上表现较好                 |
| 归纳偏差       | 减少了CNN固有的一些假设，更具灵活性      | 具有归纳偏差，有助于处理常见的视觉任务 |

## ViT的优缺点

优点：具有全局性，不限于局部特征；没有固有偏差，更灵活，能够学习更复杂的模式；在大规模数据集上训练，性能杠杠的

缺点：数据需求高，对于中小数据集还不如卷积神经网络；计算复杂度高

我认为呢，把自然语言处理的发放引用到图像处理，本就是很创新的想法，虽说对数据集要求较高，但也展现了极大的潜力。去搜了一下现在已经有了很多将ViT和CNN结合的模型，我相信以后也会有更多更优秀的模型，说不定我还能提出一个呢(开个玩笑，现在的我肯定是不行的，基础都没学明白呢，有些时候一段文字要对GPT发起几连问，bushi)